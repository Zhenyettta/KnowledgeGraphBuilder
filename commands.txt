
 ./llama-server --model /Users/evgenijanisimov/infa/Python/models/Hermes-3-Llama-3.1-8B.Q8_0.gguf --host 0.0.0.0 --port 8080


docker build -t my-neo4j .


llama-server.exe --model "C:\infa\Python\Dyplom\models\Hermes-3-Llama-3.1-8B.Q8_0.gguf" --port 8080 --n-gpu-layers 1000